{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Weather resource: https://www.timeanddate.com/weather/@2176947\n",
    "* Webscraping resource: https://stackoverflow.com/questions/51756775/scraping-table-from-website-timeanddate-com\n",
    "* Install Chromedriver: https://chromedriver.chromium.org/downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium=4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Carl\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests, re, typing\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import contextlib\n",
    "from selenium import webdriver #need to install chromedriver to iterate through day filter\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.path.abspath(\"..\\code\"))\n",
    "path = os.path.join(base_dir, r\"code\")\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove(d:list) -> list:\n",
    "    return list(filter(None, [re.sub('\\xa0', '', b) for b in d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def get_weather_data(url:str, by_url = True) -> typing.Generator[dict, None, None]:\n",
    "   d = soup(requests.get(url).text if by_url else url, 'html.parser')\n",
    "   _table = d.find('table', {'id':'wt-his'})\n",
    "   _data = [[[i.text for i in c.find_all('th')], *[i.text for i in c.find_all('td')]] for c in _table.find_all('tr')]\n",
    "   [h1], [h2], *data, _ = _data\n",
    "   _h2 = _remove(h2)\n",
    "   yield {tuple(_remove(h1)):[dict(zip(_h2, _remove([a, *i]))) for [[a], *i] in data]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_dict(chrome_dir, url):\n",
    "    d = webdriver.Chrome(chrome_dir)\n",
    "    d.get(url)\n",
    "    _d = {}\n",
    "    for i in d.find_element_by_id('wt-his-select').find_elements_by_tag_name('option'):\n",
    "        i.click()\n",
    "        with get_weather_data(d.page_source, False) as weather:\n",
    "            _d[i.text] = weather\n",
    "    d.close()\n",
    "    return _d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_humidty(_d):\n",
    "    df_all = pd.DataFrame()\n",
    "    for date, dict in _d.items():\n",
    "        for day in dict.values():\n",
    "            df = pd.DataFrame(day)\n",
    "            df.columns = [\"HUMIDITY\",\"WINDDIRECTION\", \"TEMP\", \"TIME\", \"BAROMETER\", \"WEATHER\", \"WINDSPEED\"]\n",
    "            df[\"DATE\"] = date\n",
    "            df[\"TIME\"] = df[\"TIME\"].str.split('m', expand=True)[0] + \"m\"\n",
    "            df_all = df_all.append(df)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_year = int(datetime.today().strftime('%Y'))\n",
    "this_month = int(datetime.today().strftime('%m')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Carl\\Desktop\\UNSW Capstone Project\\GitHub Capstone Project\\GroupF_Project\\data\\\\Weather - timeanddate\n"
     ]
    }
   ],
   "source": [
    "base_dir = os.path.dirname(os.path.abspath(\"..\\data\"))\n",
    "dest = os.path.join(base_dir, r\"data\") + r\"\\\\Weather - timeanddate\"\n",
    "print(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 1\n",
      "2017 2\n",
      "2017 3\n",
      "2017 4\n",
      "2017 5\n",
      "2017 6\n",
      "2017 7\n",
      "2017 8\n",
      "2017 9\n",
      "2017 10\n",
      "2017 11\n",
      "2017 12\n",
      "2018 1\n",
      "2018 2\n",
      "2018 3\n",
      "2018 4\n",
      "2018 5\n",
      "2018 6\n",
      "2018 7\n",
      "2018 8\n",
      "2018 9\n",
      "2018 10\n",
      "2018 11\n",
      "2018 12\n",
      "2019 1\n",
      "2019 2\n",
      "2019 3\n",
      "2019 4\n",
      "2019 5\n",
      "2019 6\n",
      "2019 7\n",
      "2019 8\n",
      "2019 9\n",
      "2019 10\n",
      "2019 11\n",
      "2019 12\n",
      "2020 1\n",
      "2020 2\n",
      "2020 3\n",
      "2020 4\n",
      "2020 5\n",
      "2020 6\n",
      "2020 7\n",
      "2020 8\n",
      "2020 9\n",
      "2020 10\n",
      "2020 11\n",
      "2020 12\n",
      "2021 1\n",
      "2021 2\n",
      "2021 3\n",
      "2021 4\n",
      "2021 5\n",
      "2021 6\n",
      "2021 7\n",
      "2021 8\n",
      "2021 9\n",
      "2021 10\n",
      "2021 11\n",
      "2021 12\n",
      "2022 1\n",
      "2022 2\n",
      "2022 3\n",
      "2022 4\n",
      "2022 5\n",
      "2022 6\n",
      "2022 7\n",
      "2022 8\n",
      "2022 9\n",
      "2022 10\n",
      "2022 11\n",
      "2022 12\n"
     ]
    }
   ],
   "source": [
    "start_year = 2017\n",
    "end_year = 2022\n",
    "df_summary = pd.DataFrame()\n",
    "for year in range(start_year, end_year+1):\n",
    "    if year > this_year: break\n",
    "    for month in range(1, 13):\n",
    "        if (year == this_year) & (month > this_month): break\n",
    "        print(year, month)\n",
    "        url = f'https://www.timeanddate.com/weather/@2176947/historic?month={month}&year={year}'\n",
    "        chrome_dir = path + r'\\Archive\\chromedriver' #insert path to installed chromedriver (exe file)\n",
    "        _d = get_weather_dict(chrome_dir, url)\n",
    "        df = get_daily_humidty(_d)\n",
    "        df_summary = df_summary.append(df) \n",
    "    file_name = f\"weather - {year}.csv\"\n",
    "    df_summary.to_csv(dest + \"\\\\\" + file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
